{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk.classify.util\n",
    "from nltk.metrics import *\n",
    "import collections\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier, SklearnClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(uri):\n",
    "    with open(uri, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "    output = [line.strip().decode('cp1252') for line in lines]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(neg_sents, pos_sents, seed):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(neg_sents)\n",
    "    negcutoff = int(len(neg_sents)*0.75)\n",
    "    random.shuffle(pos_sents)\n",
    "    poscutoff = int(len(pos_sents)*0.75)    \n",
    "    negtrain = neg_sents[:negcutoff]\n",
    "    negtest = neg_sents[negcutoff:]\n",
    "    postrain = pos_sents[:poscutoff]\n",
    "    postest = pos_sents[poscutoff:]\n",
    "    return {'negtrain':negtrain, 'negtest':negtest, 'postrain':postrain, 'postest':postest }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(sent):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    filtered = [word for word in sent if word not in stop_words]\n",
    "    stemmed = [stemmer.stem(word) for word in filtered] \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_unigram_bow(sent, pre_flag = False):\n",
    "    tokens = word_tokenize(sent)\n",
    "    if pre_flag == True:\n",
    "        tokens = pre_process(tokens)\n",
    "    return dict([(token, True) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_bigram_bow(sent, pre_flag = False):\n",
    "    tokens = word_tokenize(sent)\n",
    "    if pre_flag == True:\n",
    "        tokens = pre_process(tokens)\n",
    "    bigrams=ngrams(tokens,2)\n",
    "    return dict([(bigram, True) for bigram in bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_trigram_bow(sent, pre_flag = False):\n",
    "    tokens = word_tokenize(sent)\n",
    "    if pre_flag == True:\n",
    "        tokens = pre_process(tokens)\n",
    "    trigrams=ngrams(tokens,3)\n",
    "    return dict([(trigram, True) for trigram in trigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_uni_bigram_bow(sent, pre_flag = False):\n",
    "    unigram = feature_unigram_bow(sent,pre_flag)\n",
    "    bigram = feature_bigram_bow(sent,pre_flag)\n",
    "    unigram.update(bigram)\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_uni_bi_trigram_bow(sent, pre_flag = False):\n",
    "    unigram = feature_unigram_bow(sent,pre_flag)\n",
    "    bigram = feature_bigram_bow(sent,pre_flag)\n",
    "    trigram = feature_trigram_bow(sent,pre_flag)\n",
    "    unigram.update(bigram)\n",
    "    unigram.update(trigram)\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_tfidf(sents, min_df, max_df):\n",
    "    vectorizer = TfidfVectorizer(min_df = min_df,max_df = max_df,sublinear_tf=True, use_idf=True,stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(sents) \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NB_CV_classifier(corpus, labels , fold, feature, pre_flag = False):\n",
    "    kf = StratifiedKFold(n_splits=fold)      \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    for train_index, test_index in kf.split(corpus,labels):\n",
    "        X_train = [corpus[i] for i in train_index]\n",
    "        X_test = [corpus[i] for i in test_index]\n",
    "        y_train = [labels[i] for i in train_index]\n",
    "        y_test = [labels[i] for i in test_index]\n",
    "        train_feats = [feature(sent,pre_flag) for sent in X_train]\n",
    "        training_set = list(zip(train_feats, y_train))\n",
    "        test_feats = [feature(sent,pre_flag) for sent in X_test]\n",
    "        test_set = list(zip(test_feats, y_test))\n",
    "        classifier = NaiveBayesClassifier.train(training_set)\n",
    "        pred = classifier.classify_many(test_feats)\n",
    "        cm = ConfusionMatrix(pred, y_test)\n",
    "        accuracy.append(nltk.classify.accuracy(classifier, test_set))\n",
    "        TN = cm.__getitem__(('neg','neg'))\n",
    "        TP = cm.__getitem__(('pos','pos'))\n",
    "        FN = cm.__getitem__(('neg','pos'))\n",
    "        FP = cm.__getitem__(('pos','neg'))\n",
    "        precision.append(TP/(TP+FP))\n",
    "        recall.append(TP/(TP+FN))\n",
    "        fscore.append(2*(TP/(TP+FN))*(TP/(TP+FP))/((TP/(TP+FP)) +(TP/(TP+FN))))\n",
    "    accuracy = sum(accuracy)/len(accuracy)\n",
    "    precision = sum(precision)/len(precision)\n",
    "    recall = sum(recall)/len(recall)\n",
    "    fscore = sum(fscore)/len(fscore)\n",
    "    print([accuracy,precision,recall,fscore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM_CV_classifier(corpus, labels , fold, feature, pre_flag = False):\n",
    "    kf = StratifiedKFold(n_splits=fold)      \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    for train_index, test_index in kf.split(corpus,labels):\n",
    "        X_train = [corpus[i] for i in train_index]\n",
    "        X_test = [corpus[i] for i in test_index]\n",
    "        y_train = [labels[i] for i in train_index]\n",
    "        y_test = [labels[i] for i in test_index]\n",
    "        train_feats = [feature(sent,pre_flag) for sent in X_train]\n",
    "        training_set = list(zip(train_feats, y_train))\n",
    "        test_feats = [feature(sent,pre_flag) for sent in X_test]\n",
    "        test_set = list(zip(test_feats, y_test))\n",
    "        classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "        classifier.train(training_set)\n",
    "        pred = classifier.classify_many(test_feats)\n",
    "        cm = ConfusionMatrix(pred, y_test)\n",
    "        accuracy.append(nltk.classify.accuracy(classifier, test_set))\n",
    "        TN = cm.__getitem__(('neg','neg'))\n",
    "        TP = cm.__getitem__(('pos','pos'))\n",
    "        FN = cm.__getitem__(('neg','pos'))\n",
    "        FP = cm.__getitem__(('pos','neg'))\n",
    "        precision.append(TP/(TP+FP))\n",
    "        recall.append(TP/(TP+FN))\n",
    "        fscore.append(2*(TP/(TP+FN))*(TP/(TP+FP))/((TP/(TP+FP)) +(TP/(TP+FN))))\n",
    "    accuracy = sum(accuracy)/len(accuracy)\n",
    "    precision = sum(precision)/len(precision)\n",
    "    recall = sum(recall)/len(recall)\n",
    "    fscore = sum(fscore)/len(fscore)\n",
    "    print([accuracy,precision,recall,fscore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_file = read_file('/home/lingwei_shu/sentiment_analysis/rt-polarity.neg')\n",
    "pos_file = read_file('/home/lingwei_shu/sentiment_analysis/rt-polarity.pos')\n",
    "seed = 1234\n",
    "train_test = train_test_split(neg_file,pos_file,seed )\n",
    "negtrain = train_test['negtrain']\n",
    "postrain = train_test['postrain']\n",
    "corpus = negtrain + postrain\n",
    "labels = np.array(['neg'] * len(negtrain) + ['pos'] * len(postrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7618869047619048, 0.7468986556484418, 0.7926522556390978, 0.7689807718992656]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_unigram_bow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7687575187969925, 0.7600870825673958, 0.7868959899749373, 0.7729349159270598]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_unigram_bow, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6265642230576441, 0.6002244843593164, 0.7586309523809524, 0.6701561333021071]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_bigram_bow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7253671679197995, 0.7174089800270735, 0.7436290726817042, 0.7302207685854503]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_bigram_bow, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5238881578947369, 0.5127577532822329, 0.9607337092731829, 0.6686346826476888]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_trigram_bow,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6365682957393484, 0.6147625971225285, 0.7321253132832081, 0.6682365562486183]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_trigram_bow,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7656340852130324, 0.7539507224087441, 0.7886466165413533, 0.77083119569254]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_uni_bigram_bow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.777264097744361, 0.768550873004539, 0.7938984962406015, 0.7808512677099858]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_uni_bigram_bow, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7641343984962405, 0.7526613084052188, 0.7868953634085212, 0.769333406649152]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_uni_bi_trigram_bow,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773639097744361, 0.7663868512570801, 0.7878991228070176, 0.7768045648838927]\n"
     ]
    }
   ],
   "source": [
    "NB_CV_classifier(corpus, labels , 10, feature_uni_bi_trigram_bow,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.45\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.5\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.55\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.6\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.65\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.7\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.75\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.8\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.85\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.9\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 0.95\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "0 1.0\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.4\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.45\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.5\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.55\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.6\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.65\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.7\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.75\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.8\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.85\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.9\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 0.95\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "1 1.0\n",
      "[[ 2944.  1054.]\n",
      " [ 1013.  2985.]]\n",
      "[[ 2980.  1018.]\n",
      " [  879.  3119.]]\n",
      "2 0.4\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.45\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.5\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.55\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.6\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.65\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.7\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.75\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.8\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.85\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.9\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 0.95\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "2 1.0\n",
      "[[ 2924.  1074.]\n",
      " [ 1071.  2927.]]\n",
      "[[ 3024.   974.]\n",
      " [  925.  3073.]]\n",
      "3 0.4\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.45\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.5\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.55\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.6\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.65\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.7\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.75\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.8\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.85\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.9\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 0.95\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "3 1.0\n",
      "[[ 2881.  1117.]\n",
      " [ 1064.  2934.]]\n",
      "[[ 3009.   989.]\n",
      " [  946.  3052.]]\n",
      "4 0.4\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.45\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.5\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.55\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.6\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.65\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.7\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.75\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.8\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.85\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.9\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 0.95\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "4 1.0\n",
      "[[ 2876.  1122.]\n",
      " [ 1086.  2912.]]\n",
      "[[ 2995.  1003.]\n",
      " [  991.  3007.]]\n",
      "5 0.4\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.45\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.5\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.55\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.6\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.65\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.7\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.75\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.8\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.85\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.9\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 0.95\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "5 1.0\n",
      "[[ 2874.  1124.]\n",
      " [ 1116.  2882.]]\n",
      "[[ 2983.  1015.]\n",
      " [ 1030.  2968.]]\n",
      "6 0.4\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.45\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.5\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.55\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.6\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.65\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.7\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.75\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.8\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.85\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.9\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 0.95\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "6 1.0\n",
      "[[ 2859.  1139.]\n",
      " [ 1142.  2856.]]\n",
      "[[ 2952.  1046.]\n",
      " [ 1040.  2958.]]\n",
      "7 0.4\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.45\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.5\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.55\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.6\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.65\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.7\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.75\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.8\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.85\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.9\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 0.95\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "7 1.0\n",
      "[[ 2821.  1177.]\n",
      " [ 1126.  2872.]]\n",
      "[[ 2916.  1082.]\n",
      " [ 1049.  2949.]]\n",
      "8 0.4\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.45\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.5\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.55\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.65\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.7\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.75\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.8\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.85\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.9\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 0.95\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "8 1.0\n",
      "[[ 2815.  1183.]\n",
      " [ 1153.  2845.]]\n",
      "[[ 2892.  1106.]\n",
      " [ 1073.  2925.]]\n",
      "9 0.4\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.45\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.5\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.55\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.6\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.65\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.7\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.75\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.8\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.85\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.9\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 0.95\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n",
      "9 1.0\n",
      "[[ 2797.  1201.]\n",
      " [ 1180.  2818.]]\n",
      "[[ 2896.  1102.]\n",
      " [ 1116.  2882.]]\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10)\n",
    "min_array = list(range(10))\n",
    "max_array = np.arange(start = 0.4, stop = 1.05, step = 0.05)\n",
    "accurMatNB = np.zeros((len(min_array),len(max_array)))  \n",
    "accurMatSVM = np.zeros((len(min_array),len(max_array)))  \n",
    "for i in range(len(min_array)):\n",
    "    for j in range(len(max_array)):\n",
    "        print(min_array[i],max_array[j])\n",
    "        totalsvm = 0          \n",
    "        totalNB = 0\n",
    "        totalMatSvm = np.zeros((2,2))  \n",
    "        totalMatNB = np.zeros((2,2))\n",
    "        for train_index, test_index in kf.split(corpus,labels):\n",
    "            X_train = [corpus[i] for i in train_index]\n",
    "            X_test = [corpus[i] for i in test_index]\n",
    "            y_train = [labels[i] for i in train_index]\n",
    "            y_test = [labels[i] for i in test_index]\n",
    "            vectorizer = TfidfVectorizer(min_df = min_array[i],max_df = max_array[j],sublinear_tf=True, use_idf=True,stop_words='english')\n",
    "            train_corpus_tf_idf = vectorizer.fit_transform(X_train) \n",
    "            test_corpus_tf_idf = vectorizer.transform(X_test)\n",
    "\n",
    "            model1 = LinearSVC()\n",
    "            model2 = MultinomialNB()    \n",
    "            model1.fit(train_corpus_tf_idf,y_train)\n",
    "            model2.fit(train_corpus_tf_idf,y_train)\n",
    "            result1 = model1.predict(test_corpus_tf_idf)\n",
    "            result2 = model2.predict(test_corpus_tf_idf)\n",
    "\n",
    "            totalMatSvm = totalMatSvm + confusion_matrix(y_test, result1)\n",
    "            totalMatNB = totalMatNB + confusion_matrix(y_test, result2)\n",
    "            totalsvm = totalsvm+sum(y_test==result1)\n",
    "            totalNB = totalNB+sum(y_test==result2)\n",
    "\n",
    "        print(totalMatSvm)\n",
    "        accurMatSVM[i,j] = totalsvm/7996\n",
    "        print(totalMatNB)\n",
    "        accurMatNB[i,j] = totalNB/7996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76275638,  0.76275638,  0.76275638,  0.76275638,  0.76275638,\n",
       "         0.76275638,  0.76275638,  0.76275638,  0.76275638,  0.76275638,\n",
       "         0.76275638,  0.76275638,  0.76275638],\n",
       "       [ 0.76275638,  0.76275638,  0.76275638,  0.76275638,  0.76275638,\n",
       "         0.76275638,  0.76275638,  0.76275638,  0.76275638,  0.76275638,\n",
       "         0.76275638,  0.76275638,  0.76275638],\n",
       "       [ 0.76250625,  0.76250625,  0.76250625,  0.76250625,  0.76250625,\n",
       "         0.76250625,  0.76250625,  0.76250625,  0.76250625,  0.76250625,\n",
       "         0.76250625,  0.76250625,  0.76250625],\n",
       "       [ 0.758004  ,  0.758004  ,  0.758004  ,  0.758004  ,  0.758004  ,\n",
       "         0.758004  ,  0.758004  ,  0.758004  ,  0.758004  ,  0.758004  ,\n",
       "         0.758004  ,  0.758004  ,  0.758004  ],\n",
       "       [ 0.75062531,  0.75062531,  0.75062531,  0.75062531,  0.75062531,\n",
       "         0.75062531,  0.75062531,  0.75062531,  0.75062531,  0.75062531,\n",
       "         0.75062531,  0.75062531,  0.75062531],\n",
       "       [ 0.74424712,  0.74424712,  0.74424712,  0.74424712,  0.74424712,\n",
       "         0.74424712,  0.74424712,  0.74424712,  0.74424712,  0.74424712,\n",
       "         0.74424712,  0.74424712,  0.74424712],\n",
       "       [ 0.73911956,  0.73911956,  0.73911956,  0.73911956,  0.73911956,\n",
       "         0.73911956,  0.73911956,  0.73911956,  0.73911956,  0.73911956,\n",
       "         0.73911956,  0.73911956,  0.73911956],\n",
       "       [ 0.73349175,  0.73349175,  0.73349175,  0.73349175,  0.73349175,\n",
       "         0.73349175,  0.73349175,  0.73349175,  0.73349175,  0.73349175,\n",
       "         0.73349175,  0.73349175,  0.73349175],\n",
       "       [ 0.72748874,  0.72748874,  0.72748874,  0.72748874,  0.72748874,\n",
       "         0.72748874,  0.72748874,  0.72748874,  0.72748874,  0.72748874,\n",
       "         0.72748874,  0.72748874,  0.72748874],\n",
       "       [ 0.72261131,  0.72261131,  0.72261131,  0.72261131,  0.72261131,\n",
       "         0.72261131,  0.72261131,  0.72261131,  0.72261131,  0.72261131,\n",
       "         0.72261131,  0.72261131,  0.72261131]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurMatNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74149575,  0.74149575,  0.74149575,  0.74149575,  0.74149575,\n",
       "         0.74149575,  0.74149575,  0.74149575,  0.74149575,  0.74149575,\n",
       "         0.74149575,  0.74149575,  0.74149575],\n",
       "       [ 0.74149575,  0.74149575,  0.74149575,  0.74149575,  0.74149575,\n",
       "         0.74149575,  0.74149575,  0.74149575,  0.74149575,  0.74149575,\n",
       "         0.74149575,  0.74149575,  0.74149575],\n",
       "       [ 0.73174087,  0.73174087,  0.73174087,  0.73174087,  0.73174087,\n",
       "         0.73174087,  0.73174087,  0.73174087,  0.73174087,  0.73174087,\n",
       "         0.73174087,  0.73174087,  0.73174087],\n",
       "       [ 0.72723862,  0.72723862,  0.72723862,  0.72723862,  0.72723862,\n",
       "         0.72723862,  0.72723862,  0.72723862,  0.72723862,  0.72723862,\n",
       "         0.72723862,  0.72723862,  0.72723862],\n",
       "       [ 0.72386193,  0.72386193,  0.72386193,  0.72386193,  0.72386193,\n",
       "         0.72386193,  0.72386193,  0.72386193,  0.72386193,  0.72386193,\n",
       "         0.72386193,  0.72386193,  0.72386193],\n",
       "       [ 0.71985993,  0.71985993,  0.71985993,  0.71985993,  0.71985993,\n",
       "         0.71985993,  0.71985993,  0.71985993,  0.71985993,  0.71985993,\n",
       "         0.71985993,  0.71985993,  0.71985993],\n",
       "       [ 0.71473237,  0.71473237,  0.71473237,  0.71473237,  0.71473237,\n",
       "         0.71473237,  0.71473237,  0.71473237,  0.71473237,  0.71473237,\n",
       "         0.71473237,  0.71473237,  0.71473237],\n",
       "       [ 0.71198099,  0.71198099,  0.71198099,  0.71198099,  0.71198099,\n",
       "         0.71198099,  0.71198099,  0.71198099,  0.71198099,  0.71198099,\n",
       "         0.71198099,  0.71198099,  0.71198099],\n",
       "       [ 0.70785393,  0.70785393,  0.70785393,  0.70785393,  0.70785393,\n",
       "         0.70785393,  0.70785393,  0.70785393,  0.70785393,  0.70785393,\n",
       "         0.70785393,  0.70785393,  0.70785393],\n",
       "       [ 0.70222611,  0.70222611,  0.70222611,  0.70222611,  0.70222611,\n",
       "         0.70222611,  0.70222611,  0.70222611,  0.70222611,  0.70222611,\n",
       "         0.70222611,  0.70222611,  0.70222611]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurMatSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7212377959824934, 0.7432364007529033, 0.6781506003815508, 0.7087010915547691]\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "negtest = train_test['negtest']\n",
    "postest = train_test['postest']\n",
    "corpus = negtest + postest\n",
    "labels = np.array(['neg'] * len(negtest) + ['pos'] * len(postest))\n",
    "NB_CV_classifier(corpus, labels , 10, feature_uni_bigram_bow, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
